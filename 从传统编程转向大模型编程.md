# 从传统编程转向大模型编程：一次工程师的角色重塑

> **核心目标**：从“代码产出者”变成“文档定义者”

这篇文档不是教你怎么把 `Ctrl+C` / `Ctrl+V` 换成“让 AI 写代码”，而是希望帮你完成一次根本性的角色转换：

> **Code is generated, Document is the Source of Truth**  
> （代码是生成的，文档才是真理之源）

- **以前**：你亲自写代码，文档只是代码的“解释说明”（经常过期）。  
- **以后**：你负责定义核心意图并监管 AI 生成的文档（需求、架构、约束），AI 负责把文档“编译”成代码。

你不再是砌砖的工匠，而是画图纸的建筑师。你的核心产出不再是 `FunctionImpl`，而是 `RequirementSpec` 和 `ArchitectureDesign`。

---

## 最终目标

在安全合规前提下，把“写代码”变成一种“自动化生成”过程，人力主要花在：

1. **需求澄清与拆解**（把模糊的想法变成清晰的文档）；
2. **架构与边界设计**（定义 AI 的活动范围）；
3. **文档对齐与验收**（检查代码是否忠实实现了文档）。

如果我们真的把这些事情做扎实，大概会发生几件很具体的变化：

- **文档即代码**：只要文档改了，代码就能跟着变。修改功能不再是“改代码 → 改文档”，而是“改文档 → AI 重写代码”。
- **模型无关性**：只要文档写得够细，用 GPT 还是用 Claude，区别只在于生成的快慢，而不会偏离核心逻辑。
- **知识资产化**：团队沉淀下来的不再是一堆只有原作者能看懂的代码，而是一套套清晰的、可复用的业务逻辑文档。

> 不管你是程序员、测试还是产品、设计师，今天都应该大用特用大模型写代码和文档——越早把它融进日常工作，越不容易被“会用 AI 的人”替代。

![图示：角色转变](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/QvjnA3j85k6X2OXo/img/76d5b564-84e9-4687-ab22-15d5b3379c50.png)

> 当然这对我们这些已经在岗的人反而是个好消息：35 岁不一定要被“优化”，只要你会用模型，完全可以带着一队 AI 再干几十年。  
> 这不是“立刻变成科幻世界”，而是一个可以在几个月内逐步感受到的现实改进。

---

## 1. 为什么要用大模型编程？

大模型编程（LLM‑based Programming）的核心变化，是从关注 “怎么做（How）” 转向 “需要什么（What）”。

| 维度 | 传统方式 | 大模型编程带来的变化 |
|------|----------|----------------------|
| 核心产出 | 代码 (Code) | 文档 (Document) |
| 开发效率 | 人写代码、写测试、写文档 | 人定义意图，AI 生成文档与代码，迭代速度明显加快 |
| 复杂逻辑 | 自己设计规则 / 算法 | 模型可以直接处理自然语言、日志、半结构化数据 |
| 门槛 | 需要熟练掌握语言/框架细节 | 用自然语言组织需求就能起步，代码细节更多交给模型 |
| 形态 | 一次写完一大坨代码 | 文档驱动：生成文档 (AI) → 确认文档 (Human) → 生成代码 (AI) |

### 1.1 一个真实的转变经历

2023 年我还在微软时，GPT 刚刚兴起，大家已经开始尝试用大模型辅助处理一些代码问题。当时微软也在开发基于大模型的 Copilot，但受限于模型能力，功能还比较基础——只能帮忙添加注释、生成简单的单元测试，离真正“会写代码”还有很大差距。

然而短短一年多后，到了 2024 年底，我已经能用 Cursor / Claude Code 完成几乎所有的编码任务。过去一年多，我几乎没有真正“手写”过代码。不仅是我，我认识的很多程序员也是如此：日常工作的重心转向了系统设计、任务拆解和代码 Review，具体的实现则交给 AI 模型。

加入现在的团队后，尽管我没有任何该技术栈的工程经验，依然能快速完成开发需求，产出的代码质量较高，也能很好地与团队现有的代码风格保持一致，这全倚仗大模型的帮忙。

> 所以我非常确信：未来一定是大模型编码的世界，学习大模型编程会像学习使用 IDE 一样，成为一项最基本的工程师技能。

![图示：AI 编程工作流](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/QvjnA3j85k6X2OXo/img/a4b08183-840a-4783-bd9b-885bb50deaf0.png)

### 1.2 AI 编程带来的典型变化

| 任务类型 | 传统痛点 | AI 如何帮助 |
|----------|----------|-------------|
| 补充单元测试 | 写测试枯燥重复，容易漏边界情况 | 自动生成常见 case，人负责补充业务特殊场景 |
| 重构遗留代码 | 改动牵一发动全身，不敢下手 | 先让 AI 分析依赖关系，生成重构方案，人审核后分步执行 |
| 理解陌生代码 | 翻来覆去看调用链，费时费力 | 直接问 "这个模块做什么"，快速建立宏观认知 |
| 排查线上问题 | 日志堆积如山，定位根因困难 | 把错误栈和关键日志喂给 AI，快速得到可能原因 |
| 编写技术文档 | 需要整理思路、组织语言 | AI 生成文档骨架，人补充业务细节和决策背景 |
| Git 操作 | 需要自己手写 commit，记忆和操作复杂的 git 指令 | AI 一步到位，甄别需要提交哪些文件，自动生成 commit，识别你的意图并且自动执行，比如回滚，合并等操作 |

> 注意：以上场景的效率提升因人而异，关键是找到适合你的使用方式。

---

## 2. 人 + AI 结对编程：角色与好处

在传统软件工程里，“结对编程”是指两名开发者在同一台机器上协作：一人写代码（Driver），另一人盯整体设计和问题（Navigator），两人定期互换角色。收益主要在于：更早发现问题、更高代码质量、更快知识传递。

在大模型时代，可以把日常开发理解为一种“人 + AI 的新型结对编程”，只是角色从“人 + 人”变成了“人 + 模型”：

| 角色 | 职责 |
|------|------|
| 人类开发者 | 意图定义者 / 总编辑：口述/定义需求、审查并锁定 AI 生成的文档 (Sign-off)、验收最终结果 |
| 大模型 (AI) | 执行者 / 创作者：将意图转化为文档 (Drafting)、将文档转化为代码 (Coding)、自我纠错 |

![图示：人机结对](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/QvjnA3j85k6X2OXo/img/57584386-ee29-452f-8ef3-20295a6c441c.png)

在这个模式下，"写代码"不再是你的唯一核心技能，你更多要擅长：

- 把需求翻译成清晰的 Prompt 和约束条件；
- 设计合理的步骤（先测试、再改代码、再回归）；
- 识别模型输出中的风险和幻觉，进行二次校对。

### 2.1 会后可以立即尝试的三件事

如果你还没有开始用 AI 编程，建议从以下低风险任务开始：

1. **第一次尝试：给现有函数补充单元测试**
   - 选一个你熟悉的、逻辑相对简单的函数。
   - 复制函数代码，对 AI 说："帮我为这个函数写 5 个覆盖边界情况的单元测试"。
   - Review 生成的测试，修改不合理的 case。
   - 运行测试，根据失败情况调整。
   - **关键点**：明确说"只写测试，不改实现"。

2. **第二次尝试：理解陌生代码模块**
   - 找一个你不熟悉但需要了解的模块。
   - 把核心类/函数代码给 AI，问："这个模块的主要职责是什么？关键流程是怎样的？"
   - 对比 AI 的回答和你自己的理解。
   - **关键点**：把 AI 当成"导游"，帮你快速建立宏观认知。

3. **第三次尝试：编写技术方案文档**
   - 准备好需求描述和关键技术点。
   - 让 AI 生成文档骨架："帮我写一份技术方案，包括背景、方案设计、风险和时间规划"。
   - 补充业务细节和决策背景。
   - **关键点**：AI 负责结构化，你负责业务内容。

> **预期时间**：每次 10–20 分钟，完成后你会对 AI 的能力边界有基本认知。

### 2.2 新的工作节奏：利用“认知缓冲”对抗“代码催眠”

在使用 AI 编程时，你会发现一个显著的变化：键盘敲击声变少了，屏幕前的“等待”时间变多了（我称之为“受迫性摸鱼”）。

- **以前（手写代码）**：大脑与手指同步高速运转，处于持续的“输出模式”。
- **现在（AI 生成）**：输入 Prompt 后，需要等待模型生成 30–60 秒，这期间你无法进行任何操作。

> 请注意：这段“空窗期”不是在浪费时间，而是必要的“认知缓冲（Cognitive Buffer）”。

在大模型高速生成大量代码时，人类很容易陷入**“代码催眠”**（Code Hypnosis）状态——即看着代码流淌觉得都对，实则大脑已经麻木，失去了批判性思维。

因此，强烈建议大家**“合法化”**这段等待时间：

- **强制抽离**：在 AI 生成的几十秒内，允许视线短暂离开屏幕，或者清空大脑。这能让你在下一秒 Review 代码时，保持“像看陌生人代码一样”的敏锐度。
- **思维预演**：利用这段间隙，跳出具体语法，在脑中预演逻辑的边界情况，而不是盯着光标发呆。
- **节奏切换**：从“连续的高频输出”转变为“脉冲式的决策—休息—决策”。

> **给团队的共识**：在 AI 时代，不要用“是否一直在敲键盘”来衡量工作饱和度。一个对着屏幕静默思考、正在进行“认知重组”的工程师，往往比一个被 AI 带着跑的工程师，更能守住系统的安全底线。

---

## 3. 模型、工具与技巧

### 3.1 模型选择决策树

不要死记某个具体版本"最强"，模型迭代很快。

![模型选择决策树](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/QvjnA3j85k6X2OXo/img/899bbd51-9abf-4529-aa3b-df345267ddcb.jpeg)

更实用的方式是按决策流程选择：

![模型选择流程图](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/QvjnA3j85k6X2OXo/img/f06cb98a-f7e8-4f6a-9a23-1c3aca140fe5.png)

> **使用口诀**：安全第一，复杂度第二，成本第三。

#### 常见模型类型参考

| 类型 | 代表 | 适用场景 |
|------|------|----------|
| 外部高性能模型 | GPT-5/4o、Claude 3.5/4.5、Gemini 1.5/3 | 复杂重构、算法设计、整体架构建议等（前提是无敏感代码） |
| 内部/私有化模型 | 企业自研模型、LLaMA-3-Enterprise | C3 及以上敏感代码、含用户数据的场景 |

**使用原则**：
- 先看安全等级，再选模型：代码/数据越敏感，越应优先选内部合规模型。
- 不要依赖单一模型的"个人口碑"，要结合当前任务 + 实测效果来选择。

### 3.2 常见工具形态

| 工具 | 类型 | 简要说明 |
|------|------|----------|
| Cursor / Windsurf | IDE | 和大模型深度集成的编辑器，适合重度 AI 编程，但需注意仓库安全策略、费用和配额 |
| Claude Code / Aider | 命令行 | 把模型当成“远程结对伙伴”，适合本地仓库 + 终端工作流 |
| VSCode / JetBrains 插件 | IDE 插件 | 如 GitHub Copilot、通义灵码等，适合集成到现有开发环境 |
| 企业内部工具 | Web/CLI | 通常集成了企业内网模型与合规配置，适合高安全场景（如银行、互联网大厂内部平台） |

**实际使用建议**：
- 非敏感仓库：Cursor + 外部高性能模型；
- 核心保密仓库：内部 CLI + 内部模型，配置 `.ignore` 策略防止外传。

### 3.3 提示词工程：个人 Prompt 模板

大模型的“聪明程度”一半来自模型本身，另一半来自你给的提示词（Prompt）。建议为每个模型准备一份固定提示词文件，例如 `claude.md`、`gpt.md`。

一个实用的个人 Prompt 模板通常包含：

- **引用文档**：不要口述复杂逻辑，请直接引用 URL 或文件路径（`@docs/spec.md`）。
- **角色定义**：你希望模型扮演什么角色（结对工程师 / 架构师 / 文档助手等）。
- **目标与范围**：这次对话主要解决什么问题，允许/不允许碰哪些模块。
- **工作方式**：先问再改、先给方案再写代码、必须生成测试等。
- **禁止事项**：不允许拍脑袋造接口、不允许一次改太多文件、不允许忽略安全规则等。
- **输出格式**：需要列表、代码块、Diff、还是分步骤说明。
- **项目特定习惯**：日志前缀风格、错误码规范、测试框架等。

> 现在因为大模型能力的增强，已经不需要再写以前那种很长的，人设般的提示词了，但是约束型和步骤型的提示词仍然很好用。

### 3.4 进阶技巧：构建“会自我进化”的 SOP (Real-Time RL Lite)

#### 💡 核心概念：什么是 Skill / Tool？

**Skill** 是一个将“大模型的思考逻辑”（Prompt/SKILL.md）与“传统代码的执行能力”（Scripts）打包在一起的“能力插件”。

一个成熟的 Skill 包含两个核心部分：

- **大脑 (`SKILL.md`)**：AI 的决策指南。例如：“当用户要求代码审查时，请先运行下方的 Python 脚本……”
- **手脚 (`Scripts/Tools`)**：具体的执行脚本（Python/Bash/Node.js 等）。例如：`check_coverage.py`

#### 让 Skill 自我进化 (RL Lite)

操作流程：

1. **执行 (Execute)**：让 AI 读取 `SKILL.md` 并调用配套脚本执行任务。
2. **复盘 (Review)**：如果任务失败（脚本报错、AI 理解有误）。
3. **进化 (Evolve)**：
   - 修大脑：让 AI 修改 `SKILL.md` 里的判断逻辑。
   - 修手脚：让 AI 优化脚本本身（如性能重构）。

> **实战案例**：  
> 第一次它生成了不带中文注释的代码。我没有只让它重写，而是让它更新了自己的 Skill 文件。现在的 `SKILL.md` 里自动多了一行：  
> `Rule 5: All strictly business logic must have simplified Chinese comments explain the 'Why', not just the 'How'.`  
> 从此以后，我再也不用在这个问题上浪费口舌。

| 维度 | 以前的做法 | 进阶做法 (青春版 RL) |
|------|------------|----------------------|
| 对待错误 | 这次骂一顿，下次可能还犯 | 把错误转化成规则，写入 SOP |
| 资产积累 | 只有代码库 | 代码库 + 极其宝贵的经验库 (Prompts) |
| AI 角色 | 每次都要重新教的实习生 | 越用越顺手、懂你习惯的资深副手 |

---

## 4. 基于文档的开发流程 (Spec-Driven Development)

### 什么是 Spec-Driven Development (SDD)?

SDD 是一种软件开发方法论，强调在编码开始之前编写详细、结构化的规格说明书（Specifications）。采用分阶段方法：明确需求 → 创建技术方案 → 拆解任务 → 逐一实施。

> **严禁在没有文档支撑的情况下直接修改代码。**

![SDD 流程图](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/QvjnA3j85k6X2OXo/img/1cb284ca-8224-43f1-8cf8-2fd0b8f46410.png)

### 4.1 核心理念：文档即源码 (Doc as Code)

在 AI 编程时代：
- **Source Code**: `requirements.md`, `api_spec.md`, `architecture_decision.md`
- **Compiled Binary**: `UserService.java`, `main.py`
- **Compiler**: LLM (Claude, GPT, Qwen)

### 4.2 标准工作流 (The SDD Workflow)

#### Phase 1: 意图定义与文档生成 (Intent & Spec Generation)
1. **(Human)** 提供简要意图：  
   `Prompt: "我想给结算流程增加 VIP 折扣，参考现有的 Coupon 逻辑。"`
2. **(AI - Architect Agent)** 草拟技术文档：  
   生成 `docs/tasks/vip-discount.md`
3. **(Human - Sign-off)** 核心环节！  
   你必须阅读并修改文档，确保 AI 理解真实意图。**只有你“锁定”文档后，才能进入下一阶段。**

#### Phase 2: AI 编译 (AI Implementation)
- `Prompt: "请阅读 feature-xxx.md，并严格按照其中的 Steps 生成代码。"`
- 结果：AI 生成代码 Diff 或直接修改文件。

#### Phase 3: 文档验收 (Verification & Alignment)
- 如果代码逻辑不对，**不要直接改代码**，也不要只在对话框里骂 AI。
- **正确做法**：回到 `feature-xxx.md`，修改描述不清的地方，然后让 AI “重新编译”。

> 这样能确保文档永远是最新的，且换模型也能生成正确结果。

### 4.3 进阶图景：文档是 AI 智能体之间的“通信协议”

文档不再是“给人看的”，而是 **不同 AI 智能体之间的 API**。

- **产品 ↔ 开发**：  
  PM AI 生成 `Requirement_Spec.md` → Dev AI 生成 `API_Design.yaml` + `DB_Schema.sql`
- **开发 ↔ 开发**：  
  后端定义 `API_Spec.md` → 前端 AI 自动生成 TS 类型、Mock 数据、调用代码
- **开发 ↔ 测试**：  
  Dev 提供 `Design_Spec.md` → QA AI 自动生成 `Test_Cases.json` 和脚本

> **核心价值**：
> - 消除“翻译损耗”：信息以数字精度无损传递；
> - 各司其职维护：上游改文档，下游 AI 自动对齐；
> - 文档活化：成为连接产品、开发、测试的活性媒介。

---

## 5. 常见陷阱与对应策略

| 陷阱 | ❌ 错误做法 | ✅ 正确做法 |
|------|-------------|-------------|
| 上下文腐烂 | 长期保持一个 session | 用 `compact` / `clear` 清理上下文 |
| 目标漂移 | “帮我优化这个函数” → AI 重构整个类 | “只优化函数 calculateTotal，不做其他变更” |
| 幻觉/瞎编接口 | 直接使用 `StringUtils.sanitize()` | 先用 IDE 搜索确认是否存在 |
| 过度信任 | 只看 AI 解释 | 亲自看 Diff 并运行测试验证 |
| 一次要求太多 | “实现注册、登录、权限、日志” | 拆成多个小任务 |
| 规则过拟合 | 因一次特殊情况写死严苛规则 | 定期 Review 并重构 Prompt/SOP |

> **核心原则**：AI 是很厉害的实习生，不是无需审核的高级工程师。

### 进阶防守：对抗“复杂度熵增”与“最后 10% 陷阱”

- 前 90% 功能（蜜月期）非常快；
- 最后 10% 深水区（边缘 Case、上下文耦合）可能占用 20–30% 时间。

#### 5.1 核心策略：建立“文档-代码同步记录仪” (ChangeLog)

- **Code follows Doc**：所有变更必须注明依据的文档版本。
- **No Doc, No Code**：无文档支撑的代码变更是危险信号。

#### 5.2 实战落地：用 Skill 强制执行 (Auto-Flight Recorder)

**脚本 (`scripts/log_change.py`)**:
```python
import sys
from datetime import datetime

def append_log(change_type, summary, risk_analysis):
    entry = f"""## [{datetime.now().strftime('%Y-%m-%d %H:%M')}] [{change_type}]
- **Change**: {summary}
- **Risk Analysis**: {risk_analysis}   <-- 强迫 AI 思考副作用
----------------------------------------
"""
    with open("docs/AI_CHANGELOG.md", "a", encoding="utf-8") as f:
        f.write(entry)

if __name__ == "__main__":
    if len(sys.argv) < 4:
        print("Usage: python log_change.py <type> <summary> <risk>")
    else:
        append_log(sys.argv[1], sys.argv[2], sys.argv[3])
```

**Prompt 规则**:
> Rule: When you modify code, you MUST execute `scripts/log_change.py` immediately. Analyze risks seriously.

---

## 6. 安全与合规：模型接力与仓库分级

### 6.1 简化版分级思路

| 级别 | 示例 | 模型使用原则 |
|------|------|--------------|
| C3 及以上（高敏感） | 核心业务代码、含用户隐私的逻辑 | 禁止上传到公网模型；只能使用企业内部或私有化部署模型 |
| C1/C2（普通） | 通用工具库、无敏感数据的 demo | 可使用外部合规模型，但仍需遵守公司安全规定 |

> 建议为不同工具配置 `.cursorignore` 等 ignore 文件，阻止读取敏感文件。

### 6.2 模型接力（推荐范式）

1. **内部模型先读 & 脱敏**：生成脱敏后的伪代码或接口描述；
2. **外部模型生成方案**：基于脱敏内容生成实现骨架；
3. **内部验证与落地**：回到内部环境对照原代码落地。

---

## 7. 你的责任：流程设计者，而不仅是代码作者

### 个人层面
- 养成熟悉模型能力边界的习惯；
- 主动采用“测试优先 + 分步实现 + 明确约束”工作流。

### 团队层面
- 设计并推广“AI 使用规范”和“安全 Checklist”；
- 为不同仓库选好默认模型和工具组合。

> 如果说传统编程时代，你的核心资产是“你脑子里的经验”和“你写下的代码”；  
> 那么在大模型编程时代，你最宝贵的核心资产将变成：**这一整套“文档驱动的开发体系”**。

即使哪天换了模型，换了新人，只要流程和 SOP 还在，团队的战斗力就能在几分钟内恢复 80%。

> 这份文档只是一个起点，真正的价值会来自你在实际项目中不断试错、总结、微调的那套“你们自己的流程”。

---

## 附录：常见疑问 FAQ

**Q1: 用 AI 写的代码出 Bug，责任算谁的？**  
A: 算你的。AI 是工具，你是使用者和最终 Review 者。最终上线的代码质量由你负责。

**Q2: 学习 AI 编程会不会让我的编码能力退化？**  
A: 类比思考：用 IDE 自动补全不会让你忘记语法，但会让你不再记忆 API 细节。关键是理解原理而非记忆语法。AI 编程会让你编码能力重心上移，更关注系统架构。

**Q3: 我的代码会不会被模型拿去训练，泄露给别人？**  
A:  
- 企业内部/私有模型：不会，数据不出内网。  
- 外部商业 API：大部分（如 OpenAI Enterprise）承诺不用 API 数据训练，但需查阅协议。  
- 免费在线服务：可能会，务必小心。  
> **最佳实践**：敏感代码只用内部模型。

**Q4: AI 能完全取代程序员吗？**  
A: 不能，至少在可预见的未来不行。AI 很难处理含糊的需求、跨团队沟通以及为结果背锅。能熟练驾驭 AI 的工程师会替代不会用 AI 的工程师，而不是“AI 整体替代所有程序员”。

**Q5: 使用大模型效率提升了，团队是不是应该承担双倍的需求吞吐量？**  
A: 这是一个需要高度警惕的“效率陷阱”。  
虽然 AI 加快了编码，但没有缩短思考和 Review 的时间。生成越快，Review 密度要求越高。节省下来的时间应投资到更高的代码质量和更完备的测试上，而不是盲目堆砌功能。
